# 🔧 עדכון הגדרות Tokens

## ✅ מה עודכן

עדכנו את ההגדרות כדי להשתמש ברוב הטוקנים הזמינים מהקונטקסט של 8192 tokens.

### 📊 ערכים חדשים:

| הגדרה | ערך ישן | ערך חדש | הסבר |
|-------|---------|---------|------|
| `max_tokens_default` | 2000 | **5000** | Default לכל המאמרים |
| `max_tokens_short` | 1000 | **3000** | מאמרים קצרים |
| `max_tokens_long` | 3000 | **6000** | מאמרים ארוכים |
| `_generate_hebrew_article` | 1024 | **4000** | יצירת מאמר עברי |

### 📁 קבצים שעודכנו:

1. **`src/config/settings.py`** - הגדרות מרכזיות
2. **`tools/config.py`** - הגדרות ישנות (לתאימות)
3. **`src/services/article_processor.py`** - יצירת מאמרים
4. **`tools/llm_processor.py`** - עיבוד LLM ישן

### 🎯 העיקרון:

- **Context כולל**: 8192 tokens
- **מקום ל-prompt**: ~2000-3000 tokens (תלוי בגודל)
- **מקום ל-response**: 4000-6000 tokens ✅

זה מאפשר:
- ✅ מאמרים ארוכים ומפורטים יותר
- ✅ תגובות מלאות יותר מה-LLM
- ✅ שימוש יעיל ברוב הקונטקסט הזמין

### ⚠️ הערות:

1. **Timeout הוגדל ל-600 שניות** - לוקח יותר זמן לייצר יותר טקסט
2. **זיכרון**: יותר tokens = יותר זיכרון VRAM
3. **Fallback**: אם נכשל, יש fallback לקוד הישן

### 🚀 איך זה עובד כעת:

**קוד חדש:**
- יצירת מאמר ראשי: עד **4000 tokens**
- שיפור מאמר: עד **5000 tokens** (default)
- מאמר ארוך: עד **6000 tokens**

**קוד ישן (fallback):**
- משתמש ב-`LLM_OUTPUT_SETTINGS["default_max_tokens"]` = **5000**

---

**הכל מוכן! המערכת תשתמש ברוב הטוקנים הזמינים! 🎉**

