import pandas as pd
import subprocess
import json as pyjson
import re
import os

# ×§×¨×™××ª ××™×¤×•×™ ×˜×™×§×¨×™× ×œ×¡×§×˜×•×¨×™× - ×¢× ×˜×™×¤×•×œ ×‘××§×¨×” ×©×”×§×•×‘×¥ ×œ× ×§×™×™×
sector_map = {}
csv_path = "/Users/kinghippo/Documents/rssFeed/marketBit/data/flat-ui__data-Thu Jun 19 2025.csv"
if os.path.exists(csv_path):
    try:
        sector_map_df = pd.read_csv(csv_path)
        sector_map = dict(zip(sector_map_df['Tickers'], sector_map_df['GICS Sector']))
    except Exception as e:
        print(f"âš ï¸ Warning: Could not load sector mapping: {e}")
else:
    print("âš ï¸ Warning: CSV file not found, sector mapping will be empty")

# ×¤×¨×•××¤×˜ ××¢×•×“×›×Ÿ ×œ×¤×™ ×“×¨×™×©×•×ª ×”××©×ª××© â€“ ×©×›×ª×•×‘ ×‘×œ×‘×“, ×œ×œ× ×¤×¨×©× ×•×ª
def generate_prompt(original_text: str, ticker_info=None):
    company = ticker_info.get("Security") if ticker_info else ""
    sector_name = ticker_info.get("GICS Sector") if ticker_info else ""

    prompt = f"""
××ª×” ×›×•×ª×‘ ×›×ª×‘×” ××§×¦×•×¢×™×ª ×•××¨×ª×§×ª ×¢×‘×•×¨ ×’×•×£ ××—×§×¨ ×¢×¦×××™ ×‘×©× "Hippopotamus Research".

ğŸ¯ ××˜×¨×ª×š:
×œ×™×¦×•×¨ ×›×ª×‘×” ××¨×•×›×”, ××¡×•×’× × ×ª ×•××¢× ×™×™× ×ª ×”××›×¡×” ××ª ×›×œ × ×§×•×“×•×ª ×”××¤×ª×— ×©× ××¡×¨×•, ×¢× ×¡×’× ×•×Ÿ ×›×ª×™×‘×” ×¡×™×¤×•×¨×™ ×•××¨×ª×§.

ğŸ“Œ ××” ×©×§×™×‘×œ×ª:
×¨×©×™××ª × ×§×•×“×•×ª ××¤×ª×— (key points) ×¢×œ ×—×‘×¨×” ×›×œ×©×”×™, ×›×œ ××©×¤×˜ ×”×•× × ×§×•×“×ª ×¢× ×™×™×Ÿ × ×¤×¨×“×ª.

ğŸ“Œ ××” ×¢×œ×™×š ×œ×¢×©×•×ª:
1. **×›×ª×•×‘ ×›×ª×‘×” ××¨×•×›×” ×•××§×™×¤×”** - ×”××›×¡×” ××ª ×›×œ × ×§×•×“×•×ª ×”××¤×ª×— ×œ×œ× ×™×•×¦× ××Ÿ ×”×›×œ×œ
2. **×©××•×¨ ×¢×œ ×›×œ ×”× ×ª×•× ×™×** - ××¡×¤×¨×™×, ×ª××¨×™×›×™×, ×©××•×ª, ×¦×™×˜×•×˜×™× ×•××—×™×¨×™ ×™×¢×“ ×—×™×™×‘×™× ×œ×”×™×©××¨ ×‘×“×™×•×§ ×›×¤×™ ×©×”×
3. **×¦×•×¨ ××‘× ×” ××§×¦×•×¢×™ ×¢× ×¡×™××•×Ÿ ×‘×¨×•×¨** - ×”×©×ª××© ×‘××‘× ×” ×”×‘×:
   - ×›×•×ª×¨×ª ×¨××©×™×ª: ×”×ª×—×œ ××ª ×”×©×•×¨×” ×‘-#TITLE#
   - ×›×•×ª×¨×ª ××©× ×”: ×”×ª×—×œ ××ª ×”×©×•×¨×” ×‘-#SUBTITLE#
   - ×¤×¡×§×” ×¨×’×™×œ×”: ×”×ª×—×œ ××ª ×”×©×•×¨×” ×‘-#PARA#
4. **×¡×’× ×•×Ÿ ×›×ª×™×‘×” ×¡×™×¤×•×¨×™ ×•××¨×ª×§** - ×›×ª×•×‘ ×‘×¦×•×¨×” ×©××•×©×›×ª ×¢× ×™×™×Ÿ, ×¢×:
   - ×›×•×ª×¨×•×ª ××¢× ×™×™× ×•×ª ×•××¢×•×¨×¨×•×ª ×¡×§×¨× ×•×ª
   - ×©××œ×•×ª ×¨×˜×•×¨×™×•×ª ×©××¢×•×¨×¨×•×ª ××—×©×‘×”
   - ×—×™×‘×•×¨×™× ×œ×•×’×™×™× ×•×–×•×¨××™× ×‘×™×Ÿ ×”×¤×¡×§××•×ª
   - ×ª×™××•×¨×™× ×—×™×™× ×•××¨×ª×§×™×
   - ×©×™××•×© ×‘××˜××¤×•×¨×•×ª ×•××©×—×§×™ ××™×œ×™× ××ª××™××™×
5. **××§×•×¨×™×•×ª** - ××œ ×ª×—×–×•×¨ ×¢×œ ×›×•×ª×¨×•×ª ××• ××©×¤×˜×™× ×–×”×™×, ×©××•×¨ ×¢×œ ×’×™×•×•×Ÿ ×•×—×“×©× ×•×ª

ğŸ­ ×¡×’× ×•×Ÿ ×”×›×ª×™×‘×” ×”×¨×¦×•×™:
- **×›×•×ª×¨×•×ª ××¢× ×™×™× ×•×ª**: "×”××™×¨×•×¥ ×œ××¨×—×‘ ×”×¡×™×™×‘×¨", "×”××©×—×§ ×”×’×“×•×œ ×©×œ ×”×©×•×•×§×™×"
- **×©××œ×•×ª ×¨×˜×•×¨×™×•×ª**: "×”×× ×–×”×• ×¨×¥ ×¡×•×¡ ×× ×¦×— ××• ××©×œ×™×” ×§×¦×¨×ª ×˜×•×•×—?"
- **×ª×™××•×¨×™× ×—×™×™×**: "×”×× ×™×” ×”×’×™×¢×” ×œ×©×™××™× ×—×“×©×™×, ×¢× ×©×™××™ 52 ×©×‘×•×¢×•×ª ×•×©×™××™ ×›×œ ×”×–×× ×™×"
- **×—×™×‘×•×¨×™× ×–×•×¨××™×**: "×‘×¢×•×“ ×©×”×¢×•×œ× ××ª××•×“×“ ×¢×...", "×××—×•×¨×™ ×”×—×’×™×’×” ×”×–××ª..."
- **××˜××¤×•×¨×•×ª ××ª××™××•×ª**: "×”××ª×—×™× ×”×’×™××•×¤×•×œ×™×˜×™×™× ××©××©×™× ×›×“×œ×§ × ×•×¡×£"

âš ï¸ ×›×œ×œ×™× ×—×©×•×‘×™×:
- ××¡×•×¨ ×œ×©× ×•×ª ××£ × ×ª×•×Ÿ ××¡×¤×¨×™ ××• ××™×“×¢ ×—×©×•×‘
- ××¡×•×¨ ×œ×¤×¡×¤×¡ ××£ × ×§×•×“×ª ××¤×ª×— - ×›×œ ×¤×™×¡×ª ××™×“×¢ ×—×™×™×‘×ª ×œ×”×•×¤×™×¢ ×‘×›×ª×‘×”
- ××¡×•×¨ ×œ×”×•×¡×™×£ ××™×“×¢ ×—×“×© ×©×œ× ×”×™×” ×‘××§×•×¨
- ××¡×•×¨ ×œ×‘×¦×¢ × ×™×ª×•×— ××• ×ª×—×–×™×•×ª ××©×œ×š
- ×”×›×ª×‘×” ×—×™×™×‘×ª ×œ×”×™×•×ª × ××× ×” ×œ××™×“×¢ ×”××§×•×¨×™ ××š ××¡×•×’× × ×ª ×‘×›×ª×™×‘×”

âœï¸ ××‘× ×” ×”×›×ª×‘×”:
- ×©×•×¨×” ×¨××©×•× ×”: #TITLE# ×›×•×ª×¨×ª ×¨××©×™×ª ××¢× ×™×™× ×ª
- ×©×•×¨×” ×©× ×™×™×”: #SUBTITLE# ×›×•×ª×¨×ª ××©× ×” ×¨××©×•× ×”
- ×©×•×¨×” ×©×œ×™×©×™×ª: #PARA# ×¤×¡×§×” ×¨××©×•× ×”
- ×•×›×Ÿ ×”×œ××”...

ğŸ” ×—×‘×¨×”: {company}
ğŸ“‚ ×¡×§×˜×•×¨: {sector_name}

**× ×§×•×“×•×ª ×”××¤×ª×— ×”××§×•×¨×™×•×ª:**
===
{original_text}
===

âš ï¸ ×—×©×•×‘ ×××•×“: ×”×—×–×¨ ×˜×§×¡×˜ ×‘×œ×‘×“, ×›×œ ×©×•×¨×” ××ª×—×™×œ×” ×‘××—×“ ××”×‘××™×: #TITLE#, #SUBTITLE#, #PARA#. ××™×Ÿ ×œ×”×—×–×™×¨ ×ª×’×™ HTML, markdown, JSON ××• ×ª×’×™× ××—×¨×™×.
"""
    return prompt

def convert_tagged_text_to_html(text):
    """×”××¨×ª ×˜×§×¡×˜ ××¡×•××Ÿ (#TITLE#, #SUBTITLE#, #PARA#) ×œ-HTML ×ª×§× ×™"""
    html_lines = []
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        if line.startswith("#TITLE#"):
            html_lines.append(f"<h1>{line[len('#TITLE#'):].strip()}</h1>")
        elif line.startswith("#SUBTITLE#"):
            html_lines.append(f"<h2>{line[len('#SUBTITLE#'):].strip()}</h2>")
        elif line.startswith("#PARA#"):
            html_lines.append(f"<p>{line[len('#PARA#'):].strip()}</p>")
        else:
            html_lines.append(f"<p>{line}</p>")
    return '\n'.join(html_lines)

# ×”×¤×¢×œ×ª ××•×“×œ Ollama ×¢× prompt ××¢×•×“×›×Ÿ
def process_with_gemma(original_text, ticker_info=None):
    """
    Process the original text with the LLM (aya-expanse:8b) using ONLY rephrasing and restructuring rules.
    Returns the processed text as a string.
    """
    prompt = generate_prompt(original_text, ticker_info)

    if ticker_info:
        prompt += "\n---\n××™×“×¢ × ×•×¡×£ ×¢×œ ×”×—×‘×¨×”:\n"
        for k, v in ticker_info.items():
            prompt += f"{k}: {v}\n"

    prompt += "\n---\n×”×—×–×¨ ×˜×§×¡×˜ ×‘×œ×‘×“, ×›×œ ×©×•×¨×” ××ª×—×™×œ×” ×‘××—×“ ××”×‘××™×: #TITLE#, #SUBTITLE#, #PARA#. ××™×Ÿ ×œ×”×—×–×™×¨ ×ª×’×™ HTML, markdown, JSON ××• ×ª×’×™× ××—×¨×™×."

    try:
        result = subprocess.run(
            ["ollama", "run", "aya-expanse:8b"],
            input=prompt.encode("utf-8"),
            capture_output=True
        )
        output = result.stdout.decode("utf-8").strip()
        print(f"ğŸ” DEBUG: Raw LLM output (first 200 chars): {output[:200]}...")
        # × ×™×§×•×™ ×”×¤×œ×˜ ××›×œ ×¡×•×’×™ JSON ×•×ª×’×™×
        cleaned_output = clean_llm_text(output)
        print(f"ğŸ” DEBUG: After clean_llm_text (first 200 chars): {cleaned_output[:200]}...")
        # ×”×¡×¨×ª ×ª×’×™× ×•×¢×•×‘×“×•×ª ×× ×¢×“×™×™×Ÿ ×§×™×™××™×
        cleaned_output = remove_json_artifacts(cleaned_output)
        print(f"ğŸ” DEBUG: After remove_json_artifacts (first 200 chars): {cleaned_output[:200]}...")
        # ×”××¨×” ××”×¤×•×¨××˜ ×”××¡×•××Ÿ ×œ-HTML
        cleaned_output = convert_tagged_text_to_html(cleaned_output)
        print(f"ğŸ” DEBUG: After convert_tagged_text_to_html (first 200 chars): {cleaned_output[:200]}...")
        print(f"ğŸ” DEBUG: Final output contains '<h': {'<h' in cleaned_output}")
        print(f"ğŸ” DEBUG: Final output contains '<p': {'<p' in cleaned_output}")
        return cleaned_output
    except Exception as e:
        print(f"âŒ Error running ollama: {e}")
        return clean_llm_text("×©×’×™××” ×‘×¢×™×‘×•×“ LLM: " + str(e))

def remove_json_artifacts(text):
    """Remove JSON artifacts, tags, and facts from the text"""
    if not text:
        return text
    
    # ×”×¡×¨×ª JSON ××œ×
    text = re.sub(r'^\s*\{.*?"text":\s*"', '', text, flags=re.DOTALL)
    text = re.sub(r'",\s*"tags":\s*\[.*?\]\s*,\s*"facts":\s*\[.*?\]\s*\}\s*$', '', text, flags=re.DOTALL)
    text = re.sub(r'",\s*"tags":\s*\[.*?\]\s*\}\s*$', '', text, flags=re.DOTALL)
    text = re.sub(r'",\s*"facts":\s*\[.*?\]\s*\}\s*$', '', text, flags=re.DOTALL)
    text = re.sub(r'"\s*\}\s*$', '', text)
    
    # ×”×¡×¨×ª ×ª×’×™× ×•×¢×•×‘×“×•×ª ×‘×•×“×“×™×
    text = re.sub(r',\s*"tags":\s*\[.*?\]', '', text, flags=re.DOTALL)
    text = re.sub(r',\s*"facts":\s*\[.*?\]', '', text, flags=re.DOTALL)
    
    # ×”×¡×¨×ª markdown
    text = re.sub(r'```json\s*', '', text)
    text = re.sub(r'```\s*', '', text)
    
    # × ×™×§×•×™ × ×•×¡×£
    text = re.sub(r'^\s*"', '', text)
    text = re.sub(r'"\s*$', '', text)
    text = re.sub(r'\\n', '\n', text)
    text = re.sub(r'\\"', '"', text)
    
    return text.strip()

def clean_llm_text(text):
    """Clean LLM output from JSON artifacts and formatting issues"""
    if not text:
        return text
    text = re.sub(r'^\s*\{\s*', '', text)
    text = re.sub(r'\s*\}\s*$', '', text)
    text = re.sub(r'^\s*"text":\s*"', '', text)
    text = re.sub(r'^\s*"":\s*"', '', text)
    text = re.sub(r'"\s*,\s*"tags":\s*\[\s*\]\s*$', '', text)
    text = re.sub(r'"\s*$', '', text)
    text = re.sub(r'\\n', '\n', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()
