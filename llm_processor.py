import pandas as pd
import subprocess
import json as pyjson
import re

# ×§×¨×™××ª ××™×¤×•×™ ×˜×™×§×¨×™× ×œ×¡×§×˜×•×¨×™×
sector_map_df = pd.read_csv("/Users/kinghippo/Documents/rssFeed/marketBit/data/flat-ui__data-Thu Jun 19 2025.csv")
sector_map = dict(zip(sector_map_df['Tickers'], sector_map_df['GICS Sector']))

# ×¤×¨×•××¤×˜ ××¢×•×“×›×Ÿ ×œ×¤×™ ×“×¨×™×©×•×ª ×”××©×ª××© â€“ ×©×›×ª×•×‘ ×‘×œ×‘×“, ×œ×œ× ×¤×¨×©× ×•×ª
def generate_prompt(original_text: str, ticker_info=None):
    company = ticker_info.get("Security") if ticker_info else ""
    sector_name = ticker_info.get("GICS Sector") if ticker_info else ""

    prompt = f"""
××ª×” ×›×•×ª×‘ ×›×ª×‘×” ××§×¦×•×¢×™×ª ×¢×‘×•×¨ ×’×•×£ ××—×§×¨ ×¢×¦×××™ ×‘×©× "Hippopotamus Research".

ğŸ¯ ××˜×¨×ª×š:
×œ×™×¦×•×¨ ×›×ª×‘×” ××¨×•×›×”, ××¡×•×’× × ×ª ×•××¢× ×™×™× ×ª ×”××›×¡×” ××ª ×›×œ × ×§×•×“×•×ª ×”××¤×ª×— ×©× ××¡×¨×•, ×¢× ××‘× ×” ××§×¦×•×¢×™ ×•×¢×™×¦×•×‘ HTML × ×›×•×Ÿ.

ğŸ“Œ ××” ×©×§×™×‘×œ×ª:
×¨×©×™××ª × ×§×•×“×•×ª ××¤×ª×— (key points) ×¢×œ ×—×‘×¨×” ×›×œ×©×”×™, ×›×œ ××©×¤×˜ ×”×•× × ×§×•×“×ª ×¢× ×™×™×Ÿ × ×¤×¨×“×ª.

ğŸ“Œ ××” ×¢×œ×™×š ×œ×¢×©×•×ª:
1. **×›×ª×•×‘ ×›×ª×‘×” ××¨×•×›×” ×•××§×™×¤×”** - ×”××›×¡×” ××ª ×›×œ × ×§×•×“×•×ª ×”××¤×ª×— ×œ×œ× ×™×•×¦× ××Ÿ ×”×›×œ×œ
2. **×©××•×¨ ×¢×œ ×›×œ ×”× ×ª×•× ×™×** - ××¡×¤×¨×™×, ×ª××¨×™×›×™×, ×©××•×ª, ×¦×™×˜×•×˜×™× ×•××—×™×¨×™ ×™×¢×“ ×—×™×™×‘×™× ×œ×”×™×©××¨ ×‘×“×™×•×§ ×›×¤×™ ×©×”×
3. **×¦×•×¨ ××‘× ×” ××§×¦×•×¢×™ ×¢× HTML** - ×›×•×ª×¨×ª ×¨××©×™×ª ×¢× <h1>, ×›×•×ª×¨×•×ª ××©× ×” ×¢× <h2>, ×¤×¡×§××•×ª ×¢× <p>, ×•××™×•×ª ×‘×¨××” ×’×‘×•×”×”
4. **×¡×’× ×•×Ÿ ×›×ª×™×‘×” ××¢× ×™×™×Ÿ** - ×›×ª×•×‘ ×‘×¦×•×¨×” ×©××•×©×›×ª ×¢× ×™×™×Ÿ ×•×–×•×¨××ª, ×¢× ×—×™×‘×•×¨×™× ×œ×•×’×™×™× ×‘×™×Ÿ ×”×¤×¡×§××•×ª
5. **××§×•×¨×™×•×ª** - ××œ ×ª×—×–×•×¨ ×¢×œ ×›×•×ª×¨×•×ª ××• ××©×¤×˜×™× ×–×”×™×, ×©××•×¨ ×¢×œ ×’×™×•×•×Ÿ ×•×—×“×©× ×•×ª

âš ï¸ ×›×œ×œ×™× ×—×©×•×‘×™×:
- ××¡×•×¨ ×œ×©× ×•×ª ××£ × ×ª×•×Ÿ ××¡×¤×¨×™ ××• ××™×“×¢ ×—×©×•×‘
- ××¡×•×¨ ×œ×¤×¡×¤×¡ ××£ × ×§×•×“×ª ××¤×ª×— - ×›×œ ×¤×™×¡×ª ××™×“×¢ ×—×™×™×‘×ª ×œ×”×•×¤×™×¢ ×‘×›×ª×‘×”
- ××¡×•×¨ ×œ×”×•×¡×™×£ ××™×“×¢ ×—×“×© ×©×œ× ×”×™×” ×‘××§×•×¨
- ××¡×•×¨ ×œ×‘×¦×¢ × ×™×ª×•×— ××• ×ª×—×–×™×•×ª ××©×œ×š
- ×”×›×ª×‘×” ×—×™×™×‘×ª ×œ×”×™×•×ª × ××× ×” ×œ××™×“×¢ ×”××§×•×¨×™ ××š ××¡×•×’× × ×ª ×‘×›×ª×™×‘×”

âœï¸ ××‘× ×” ×”×›×ª×‘×” ×¢× HTML:
- <h1>×›×•×ª×¨×ª ×¨××©×™×ª ××¢× ×™×™× ×ª</h1>
- <h2>×›×•×ª×¨×ª ××©× ×” ×¨××©×•× ×”</h2>
- <p>×¤×¡×§×” ×¨××©×•× ×” ×¢× ×ª×•×›×Ÿ...</p>
- <h2>×›×•×ª×¨×ª ××©× ×” ×©× ×™×™×”</h2>
- <p>×¤×¡×§×” ×©× ×™×™×” ×¢× ×ª×•×›×Ÿ...</p>
- ×•×›×Ÿ ×”×œ××”...

ğŸ” ×—×‘×¨×”: {company}
ğŸ“‚ ×¡×§×˜×•×¨: {sector_name}

**× ×§×•×“×•×ª ×”××¤×ª×— ×”××§×•×¨×™×•×ª:**
===
{original_text}
===

âš ï¸ ×—×©×•×‘ ×××•×“: ×”×—×–×¨ ×›×ª×‘×” ××¢×•×¦×‘×ª ×¢× ×ª×’×™ HTML × ×›×•× ×™× (<h1>, <h2>, <p>), ×œ×œ× JSON, ×ª×’×™×, ××• markdown (#).
"""
    return prompt

# ×”×¤×¢×œ×ª ××•×“×œ Ollama ×¢× prompt ××¢×•×“×›×Ÿ
def process_with_gemma(original_text, ticker_info=None):
    """
    Process the original text with the LLM (aya-expanse:8b) using ONLY rephrasing and restructuring rules.
    Returns the processed text as a string.
    """
    prompt = generate_prompt(original_text, ticker_info)

    if ticker_info:
        prompt += "\n---\n××™×“×¢ × ×•×¡×£ ×¢×œ ×”×—×‘×¨×”:\n"
        for k, v in ticker_info.items():
            prompt += f"{k}: {v}\n"

    prompt += "\n---\n×”×—×–×¨ ×›×ª×‘×” ××¢×•×¦×‘×ª ×¢× ×ª×’×™ HTML × ×›×•× ×™× (<h1>, <h2>, <p>), ×œ×œ× JSON ××• ×ª×’×™×."

    try:
        result = subprocess.run(
            ["ollama", "run", "aya-expanse:8b"],
            input=prompt.encode("utf-8"),
            capture_output=True
        )
        output = result.stdout.decode("utf-8").strip()

        # × ×™×§×•×™ ×”×¤×œ×˜ ××›×œ ×¡×•×’×™ JSON ×•×ª×’×™×
        cleaned_output = clean_llm_text(output)
        
        # ×”×¡×¨×ª ×ª×’×™× ×•×¢×•×‘×“×•×ª ×× ×¢×“×™×™×Ÿ ×§×™×™××™×
        cleaned_output = remove_json_artifacts(cleaned_output)
        
        # ×”××¨×ª markdown ×œ-HTML ×× × ×“×¨×©
        cleaned_output = convert_markdown_to_html(cleaned_output)
        
        return cleaned_output

    except Exception as e:
        print(f"âŒ Error running ollama: {e}")
        return clean_llm_text("×©×’×™××” ×‘×¢×™×‘×•×“ LLM: " + str(e))

def remove_json_artifacts(text):
    """Remove JSON artifacts, tags, and facts from the text"""
    if not text:
        return text
    
    # ×”×¡×¨×ª JSON ××œ×
    text = re.sub(r'^\s*\{.*?"text":\s*"', '', text, flags=re.DOTALL)
    text = re.sub(r'",\s*"tags":\s*\[.*?\]\s*,\s*"facts":\s*\[.*?\]\s*\}\s*$', '', text, flags=re.DOTALL)
    text = re.sub(r'",\s*"tags":\s*\[.*?\]\s*\}\s*$', '', text, flags=re.DOTALL)
    text = re.sub(r'",\s*"facts":\s*\[.*?\]\s*\}\s*$', '', text, flags=re.DOTALL)
    text = re.sub(r'"\s*\}\s*$', '', text)
    
    # ×”×¡×¨×ª ×ª×’×™× ×•×¢×•×‘×“×•×ª ×‘×•×“×“×™×
    text = re.sub(r',\s*"tags":\s*\[.*?\]', '', text, flags=re.DOTALL)
    text = re.sub(r',\s*"facts":\s*\[.*?\]', '', text, flags=re.DOTALL)
    
    # ×”×¡×¨×ª markdown
    text = re.sub(r'```json\s*', '', text)
    text = re.sub(r'```\s*', '', text)
    
    # × ×™×§×•×™ × ×•×¡×£
    text = re.sub(r'^\s*"', '', text)
    text = re.sub(r'"\s*$', '', text)
    text = re.sub(r'\\n', '\n', text)
    text = re.sub(r'\\"', '"', text)
    
    return text.strip()

def convert_markdown_to_html(text):
    """Convert markdown formatting to proper HTML tags"""
    if not text:
        return text
    
    # × ×™×§×•×™ ×‘×¡×™×¡×™
    text = text.strip()
    
    # ×”×¡×¨×ª ×ª×’×™× ×›×¤×•×œ×™× ××• ×œ× ×ª×§×™× ×™×
    text = re.sub(r'<h1>\s*<h1>', '<h1>', text)
    text = re.sub(r'</h1>\s*</h1>', '</h1>', text)
    text = re.sub(r'<p>\s*<h1>', '<h1>', text)
    text = re.sub(r'</h1>\s*</p>', '</h1>', text)
    
    # ×”××¨×ª ×›×•×ª×¨×•×ª markdown ×œ-HTML
    text = re.sub(r'^#\s+(.+)$', r'<h1>\1</h1>', text, flags=re.MULTILINE)
    text = re.sub(r'^##\s+(.+)$', r'<h2>\1</h2>', text, flags=re.MULTILINE)
    text = re.sub(r'^###\s+(.+)$', r'<h3>\1</h3>', text, flags=re.MULTILINE)
    text = re.sub(r'^####\s+(.+)$', r'<h4>\1</h4>', text, flags=re.MULTILINE)
    
    # ×”××¨×ª ×¤×¡×§××•×ª
    lines = text.split('\n')
    processed_lines = []
    current_paragraph = []
    
    for line in lines:
        line = line.strip()
        if not line:
            # ×©×•×¨×” ×¨×™×§×” - ×¡×™×™× ××ª ×”×¤×¡×§×” ×”× ×•×›×—×™×ª
            if current_paragraph:
                processed_lines.append(f'<p>{" ".join(current_paragraph)}</p>')
                current_paragraph = []
            continue
            
        # ×× ×”×©×•×¨×” ××ª×—×™×œ×” ×¢× ×ª×’ HTML (×›×•×ª×¨×ª), ×¡×™×™× ×¤×¡×§×” ×§×™×™××ª ×•×”×ª×—×œ ×—×“×©×”
        if re.match(r'^<[^>]+>', line):
            if current_paragraph:
                processed_lines.append(f'<p>{" ".join(current_paragraph)}</p>')
                current_paragraph = []
            processed_lines.append(line)
        else:
            # ×”×•×¡×£ ×œ×©×•×¨×” ×”× ×•×›×—×™×ª
            current_paragraph.append(line)
    
    # ×”×•×¡×£ ×¤×¡×§×” ××—×¨×•× ×” ×× ×™×©
    if current_paragraph:
        processed_lines.append(f'<p>{" ".join(current_paragraph)}</p>')
    
    result = '\n'.join(processed_lines)
    
    # × ×™×§×•×™ × ×•×¡×£ ×©×œ ×ª×’×™× ×›×¤×•×œ×™× - ×ª×™×§×•×Ÿ ×”-regex
    result = re.sub(r'<p>\s*<h([1-6])>', r'<h\1>', result)
    result = re.sub(r'</h([1-6])>\s*</p>', r'</h\1>', result)
    
    return result

def clean_llm_text(text):
    """Clean LLM output from JSON artifacts and formatting issues"""
    if not text:
        return text
    text = re.sub(r'^\s*\{\s*', '', text)
    text = re.sub(r'\s*\}\s*$', '', text)
    text = re.sub(r'^\s*"text":\s*"', '', text)
    text = re.sub(r'^\s*"":\s*"', '', text)
    text = re.sub(r'"\s*,\s*"tags":\s*\[\s*\]\s*$', '', text)
    text = re.sub(r'"\s*$', '', text)
    text = re.sub(r'\\n', '\n', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()
