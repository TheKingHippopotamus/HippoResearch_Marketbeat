#!/usr/bin/env python3
"""
Text Quality Checker for Hebrew Financial Writing
×‘×•×“×§ ××™×›×•×ª ×˜×§×¡×˜ ×œ×›×ª×™×‘×” ×›×œ×›×œ×™×ª ×¢×‘×¨×™×ª
"""

import re
from typing import Dict, List, Tuple, Optional
from tools.hebrew_vocabulary import get_vocabulary_manager

class TextQualityChecker:
    """×‘×•×“×§ ××™×›×•×ª ×˜×§×¡×˜ ×¢×‘×¨×™ ×›×œ×›×œ×™"""
    
    def __init__(self):
        self.vocab_manager = get_vocabulary_manager()
        
    def check_text_quality(self, text: str) -> Dict:
        """×‘×•×“×§ ××ª ××™×›×•×ª ×”×˜×§×¡×˜ ×•××—×–×™×¨ ×“×•×— ××¤×•×¨×˜"""
        results = {
            'overall_score': 0,
            'issues': [],
            'suggestions': [],
            'grammar_errors': [],
            'style_issues': [],
            'vocabulary_score': 0,
            'flow_score': 0,
            'professionalism_score': 0
        }
        
        # ×‘×“×™×§×ª ×©×’×™××•×ª ×“×§×“×•×§
        grammar_errors = self._check_grammar(text)
        results['grammar_errors'] = grammar_errors
        
        # ×‘×“×™×§×ª ×‘×¢×™×•×ª ×¡×’× ×•×Ÿ
        style_issues = self._check_style(text)
        results['style_issues'] = style_issues
        
        # ×‘×“×™×§×ª ××•×¦×¨ ××™×œ×™×
        vocab_score = self._check_vocabulary(text)
        results['vocabulary_score'] = vocab_score
        
        # ×‘×“×™×§×ª ×–×¨×™××”
        flow_score = self._check_flow(text)
        results['flow_score'] = flow_score
        
        # ×‘×“×™×§×ª ××§×¦×•×¢×™×•×ª
        professionalism_score = self._check_professionalism(text)
        results['professionalism_score'] = professionalism_score
        
        # ×—×™×©×•×‘ ×¦×™×•×Ÿ ×›×œ×œ×™
        results['overall_score'] = self._calculate_overall_score(results)
        
        # ×™×¦×™×¨×ª ×”×¦×¢×•×ª ×œ×©×™×¤×•×¨
        results['suggestions'] = self._generate_suggestions(results)
        
        return results
    
    def _check_grammar(self, text: str) -> List[str]:
        """×‘×•×“×§ ×©×’×™××•×ª ×“×§×“×•×§ × ×¤×•×¦×•×ª"""
        errors = []
        
        # ×‘×“×™×§×ª ×¨×‘×™×/×™×—×™×“
        if re.search(r'×”××©×§×™×¢×™×\s+×™×›×•×œ\b', text):
            errors.append("×©×’×™××ª ×¨×‘×™×/×™×—×™×“: '×”××©×§×™×¢×™× ×™×›×•×œ' â†’ '×”××©×§×™×¢×™× ×™×›×•×œ×™×'")
        
        if re.search(r'×”×× ×œ×™×¡×˜×™×\s+×”×¦×™×’\b', text):
            errors.append("×©×’×™××ª ×¨×‘×™×/×™×—×™×“: '×”×× ×œ×™×¡×˜×™× ×”×¦×™×’' â†’ '×”×× ×œ×™×¡×˜×™× ×”×¦×™×’×•'")
        
        if re.search(r'×”×—×‘×¨×•×ª\s+××ª××•×“×“\b', text):
            errors.append("×©×’×™××ª ×¨×‘×™×/×™×—×™×“: '×”×—×‘×¨×•×ª ××ª××•×“×“' â†’ '×”×—×‘×¨×•×ª ××ª××•×“×“×•×ª'")
        
        # ×‘×“×™×§×ª ×‘×™×˜×•×™×™× ×©×’×•×™×™×
        if re.search(r'×©×•×§ ×”×× ×™×•×ª ×©×œ\s+', text):
            errors.append("×‘×™×˜×•×™ ×©×’×•×™: '×©×•×§ ×”×× ×™×•×ª ×©×œ' â†’ '×× ×™×™×ª'")
        
        # ×‘×“×™×§×ª ××©×¤×˜×™× ×œ× ×©×œ××™×
        if re.search(r'\w+\s+×œ,\s*', text):
            errors.append("××©×¤×˜ ×œ× ×©×œ×: ××©×¤×˜ ×©××¡×ª×™×™× ×‘-'×œ,'")
        
        # ×‘×“×™×§×ª ×¡×™×× ×™ ×¤×™×¡×•×§
        if re.search(r',\s*,', text):
            errors.append("×¡×™×× ×™ ×¤×™×¡×•×§: ×¤×¡×™×§×™× ×›×¤×•×œ×™×")
        
        if re.search(r'\.\s*\.', text):
            errors.append("×¡×™×× ×™ ×¤×™×¡×•×§: × ×§×•×“×•×ª ×›×¤×•×œ×•×ª")
        
        return errors
    
    def _check_style(self, text: str) -> List[str]:
        """×‘×•×“×§ ×‘×¢×™×•×ª ×¡×’× ×•×Ÿ"""
        issues = []
        
        # ×‘×“×™×§×ª ××™×œ×•×ª ×§×™×©×•×¨
        connection_words = ['×™×ª×¨ ×¢×œ ×›×Ÿ', '×œ×¢×•××ª ×–××ª', '×‘× ×•×¡×£', '×œ×¤×™×›×š', '××¦×“ ××—×“', '××¦×“ ×©× ×™']
        found_connections = sum(1 for word in connection_words if word in text)
        
        if found_connections < 2:
            issues.append("×—×¡×¨×•×ª ××™×œ×•×ª ×§×™×©×•×¨: ××•××œ×¥ ×œ×”×©×ª××© ×‘×™×•×ª×¨ ××™×œ×•×ª ×§×™×©×•×¨ ×œ×–×¨×™××” ×˜×•×‘×” ×™×•×ª×¨")
        
        # ×‘×“×™×§×ª ××•×¨×š ××©×¤×˜×™×
        sentences = re.split(r'[.!?]', text)
        long_sentences = [s for s in sentences if len(s.split()) > 25]
        
        if len(long_sentences) > 2:
            issues.append("××©×¤×˜×™× ××¨×•×›×™× ××“×™: ××•××œ×¥ ×œ×¤×¦×œ ××©×¤×˜×™× ××¨×•×›×™×")
        
        # ×‘×“×™×§×ª ×—×–×¨×•×ª
        words = text.lower().split()
        word_counts = {}
        for word in words:
            if len(word) > 3:  # ×¨×§ ××™×œ×™× ××¨×•×›×•×ª
                word_counts[word] = word_counts.get(word, 0) + 1
        
        repeated_words = [word for word, count in word_counts.items() if count > 3]
        if repeated_words:
            issues.append(f"××™×œ×™× ×—×•×–×¨×•×ª: {', '.join(repeated_words[:3])}")
        
        return issues
    
    def _check_vocabulary(self, text: str) -> float:
        """×‘×•×“×§ ××ª ××™×›×•×ª ××•×¦×¨ ×”××™×œ×™×"""
        score = 0
        total_words = len(text.split())
        
        if total_words == 0:
            return 0
        
        # ×‘×“×™×§×ª ×©×™××•×© ×‘××™×œ×™× ××§×¦×•×¢×™×•×ª
        professional_words = [
            '×¨×•×•×—', '×”×¤×¡×“', '×¦××™×—×”', '×™×¨×™×“×”', '×ª× ×•×“×ª×™×•×ª', '××©×§×™×¢', '×× ×œ×™×¡×˜',
            '×—×‘×¨×”', '×× ×™×”', '×©×•×§', '×‘×™×¦×•×¢×™×', '×ª×—×–×™×ª', '×”×¢×¨×›×”'
        ]
        
        found_professional = sum(1 for word in professional_words if word in text)
        score += (found_professional / len(professional_words)) * 40
        
        # ×‘×“×™×§×ª ×©×™××•×© ×‘××™×œ×•×ª ×§×™×©×•×¨ ××§×¦×•×¢×™×•×ª
        connection_words = ['×™×ª×¨ ×¢×œ ×›×Ÿ', '×œ×¢×•××ª ×–××ª', '×‘× ×•×¡×£', '×œ×¤×™×›×š']
        found_connections = sum(1 for word in connection_words if word in text)
        score += (found_connections / len(connection_words)) * 30
        
        # ×‘×“×™×§×ª ×”×™×× ×¢×•×ª ×××™×œ×™× ×œ× ××§×¦×•×¢×™×•×ª
        informal_words = ['××‘×œ', '×’×', '×¤×©×•×˜', '×‘×××ª', '×××©']
        found_informal = sum(1 for word in informal_words if word in text)
        score -= (found_informal / len(informal_words)) * 30
        
        return max(0, min(100, score))
    
    def _check_flow(self, text: str) -> float:
        """×‘×•×“×§ ××ª ×–×¨×™××ª ×”×˜×§×¡×˜"""
        score = 0
        
        # ×‘×“×™×§×ª ××¢×‘×¨×™× ×˜×‘×¢×™×™×
        transitions = ['×™×ª×¨ ×¢×œ ×›×Ÿ', '×œ×¢×•××ª ×–××ª', '×‘× ×•×¡×£', '×œ×¤×™×›×š', '××¦×“ ××—×“', '××¦×“ ×©× ×™']
        found_transitions = sum(1 for transition in transitions if transition in text)
        score += (found_transitions / len(transitions)) * 40
        
        # ×‘×“×™×§×ª ××•×¨×š ×¤×¡×§××•×ª
        paragraphs = text.split('\n\n')
        good_paragraphs = sum(1 for p in paragraphs if 2 <= len(p.split()) <= 8)
        if paragraphs:
            score += (good_paragraphs / len(paragraphs)) * 30
        
        # ×‘×“×™×§×ª ××‘× ×” ×œ×•×’×™
        if '#TITLE#' in text and '#SUBTITLE#' in text and '#PARA#' in text:
            score += 30
        
        return min(100, score)
    
    def _check_professionalism(self, text: str) -> float:
        """×‘×•×“×§ ××ª ×¨××ª ×”××§×¦×•×¢×™×•×ª"""
        score = 0
        
        # ×‘×“×™×§×ª ×©×™××•×© ×‘×’×•×£ ×©×œ×™×©×™
        first_person = ['×× ×™', '×× ×—× ×•', '×× ×™', '×× ×—× ×•']
        second_person = ['××ª×”', '××ª×', '××ª', '××ª×Ÿ']
        
        first_person_count = sum(1 for word in first_person if word in text)
        second_person_count = sum(1 for word in second_person if word in text)
        
        if first_person_count == 0 and second_person_count == 0:
            score += 40  # ×©×™××•×© × ×›×•×Ÿ ×‘×’×•×£ ×©×œ×™×©×™
        
        # ×‘×“×™×§×ª ××™×œ×™× ××§×¦×•×¢×™×•×ª
        professional_terms = [
            '× ×™×ª×•×—', '×ª×—×–×™×ª', '×”×¢×¨×›×”', '×‘×™×¦×•×¢×™×', '×ª×•×¦××•×ª', '××¡×˜×¨×˜×’×™×”',
            '×©×•×§', '××©×§×™×¢', '×× ×œ×™×¡×˜', '×—×‘×¨×”', '×¨×•×•×—', '×”×¤×¡×“'
        ]
        
        found_terms = sum(1 for term in professional_terms if term in text)
        score += (found_terms / len(professional_terms)) * 30
        
        # ×‘×“×™×§×ª ×”×™×× ×¢×•×ª ×××™×œ×™× ×œ× ××§×¦×•×¢×™×•×ª
        informal_terms = ['×××©', '×‘×××ª', '×¤×©×•×˜', '×›×–×”', '×›××œ×”']
        found_informal = sum(1 for term in informal_terms if term in text)
        score -= (found_informal / len(informal_terms)) * 30
        
        return max(0, min(100, score))
    
    def _calculate_overall_score(self, results: Dict) -> float:
        """××—×©×‘ ×¦×™×•×Ÿ ×›×œ×œ×™"""
        weights = {
            'vocabulary_score': 0.25,
            'flow_score': 0.25,
            'professionalism_score': 0.25,
            'grammar_errors': 0.15,
            'style_issues': 0.10
        }
        
        score = 0
        
        # ×¦×™×•× ×™× ×—×™×•×‘×™×™×
        score += results['vocabulary_score'] * weights['vocabulary_score']
        score += results['flow_score'] * weights['flow_score']
        score += results['professionalism_score'] * weights['professionalism_score']
        
        # ×”×¤×—×ª×•×ª ×¢×œ ×©×’×™××•×ª
        grammar_penalty = len(results['grammar_errors']) * 5
        style_penalty = len(results['style_issues']) * 3
        
        score -= min(grammar_penalty, 20)  # ××§×¡×™××•× ×”×¤×—×ª×” ×©×œ 20 × ×§×•×“×•×ª
        score -= min(style_penalty, 15)    # ××§×¡×™××•× ×”×¤×—×ª×” ×©×œ 15 × ×§×•×“×•×ª
        
        return max(0, min(100, score))
    
    def _generate_suggestions(self, results: Dict) -> List[str]:
        """××™×™×¦×¨ ×”×¦×¢×•×ª ×œ×©×™×¤×•×¨"""
        suggestions = []
        
        # ×”×¦×¢×•×ª ×¢×œ ×‘×¡×™×¡ ×©×’×™××•×ª ×“×§×“×•×§
        for error in results['grammar_errors']:
            suggestions.append(f"×ª×™×§×•×Ÿ ×“×§×“×•×§: {error}")
        
        # ×”×¦×¢×•×ª ×¢×œ ×‘×¡×™×¡ ×‘×¢×™×•×ª ×¡×’× ×•×Ÿ
        for issue in results['style_issues']:
            suggestions.append(f"×©×™×¤×•×¨ ×¡×’× ×•×Ÿ: {issue}")
        
        # ×”×¦×¢×•×ª ×¢×œ ×‘×¡×™×¡ ×¦×™×•× ×™× × ××•×›×™×
        if results['vocabulary_score'] < 60:
            suggestions.append("×”×¨×—×‘×ª ××•×¦×¨ ××™×œ×™×: ×”×©×ª××© ×‘××™×œ×™× ××§×¦×•×¢×™×•×ª ×™×•×ª×¨")
        
        if results['flow_score'] < 60:
            suggestions.append("×©×™×¤×•×¨ ×–×¨×™××”: ×”×•×¡×£ ××™×œ×•×ª ×§×™×©×•×¨ ×•××¢×‘×¨×™× ×˜×‘×¢×™×™×")
        
        if results['professionalism_score'] < 60:
            suggestions.append("×”×’×‘×¨×ª ××§×¦×•×¢×™×•×ª: ×”×©×ª××© ×‘×’×•×£ ×©×œ×™×©×™ ×•×”×™×× ×¢ ×××™×œ×™× ×œ× ×¤×•×¨××œ×™×•×ª")
        
        # ×”×¦×¢×•×ª ×›×œ×œ×™×•×ª
        if results['overall_score'] < 70:
            suggestions.append("×‘×“×•×§ ××ª ×”××‘× ×” ×”×›×œ×œ×™ ×©×œ ×”×˜×§×¡×˜")
            suggestions.append("×•×•×“× ×©×›×œ ×”××©×¤×˜×™× ×©×œ××™× ×•××“×•×™×§×™×")
        
        return suggestions
    
    def get_improved_text(self, text: str) -> str:
        """××—×–×™×¨ ×’×¨×¡×” ××©×•×¤×¨×ª ×©×œ ×”×˜×§×¡×˜"""
        improved_text = text
        
        # ×ª×™×§×•×Ÿ ×©×’×™××•×ª ×“×§×“×•×§
        improved_text = re.sub(r'×”××©×§×™×¢×™×\s+×™×›×•×œ\b', '×”××©×§×™×¢×™× ×™×›×•×œ×™×', improved_text)
        improved_text = re.sub(r'×”×× ×œ×™×¡×˜×™×\s+×”×¦×™×’\b', '×”×× ×œ×™×¡×˜×™× ×”×¦×™×’×•', improved_text)
        improved_text = re.sub(r'×”×—×‘×¨×•×ª\s+××ª××•×“×“\b', '×”×—×‘×¨×•×ª ××ª××•×“×“×•×ª', improved_text)
        
        # ×ª×™×§×•×Ÿ ×‘×™×˜×•×™×™× ×©×’×•×™×™×
        improved_text = re.sub(r'×©×•×§ ×”×× ×™×•×ª ×©×œ\s+', '×× ×™×™×ª ', improved_text)
        
        # ×ª×™×§×•×Ÿ ×¡×™×× ×™ ×¤×™×¡×•×§
        improved_text = re.sub(r',\s*,', ',', improved_text)
        improved_text = re.sub(r'\.\s*\.', '.', improved_text)
        
        return improved_text
    
    def generate_quality_report(self, text: str) -> str:
        """××™×™×¦×¨ ×“×•×— ××™×›×•×ª ××¤×•×¨×˜"""
        results = self.check_text_quality(text)
        
        report = f"""
ğŸ“Š ×“×•×— ××™×›×•×ª ×˜×§×¡×˜

ğŸ¯ ×¦×™×•×Ÿ ×›×œ×œ×™: {results['overall_score']:.1f}/100

ğŸ“ˆ ×¦×™×•× ×™× ××¤×•×¨×˜×™×:
â€¢ ××•×¦×¨ ××™×œ×™×: {results['vocabulary_score']:.1f}/100
â€¢ ×–×¨×™××”: {results['flow_score']:.1f}/100
â€¢ ××§×¦×•×¢×™×•×ª: {results['professionalism_score']:.1f}/100

âŒ ×©×’×™××•×ª ×“×§×“×•×§ ({len(results['grammar_errors'])}):
"""
        
        for error in results['grammar_errors']:
            report += f"  â€¢ {error}\n"
        
        if results['style_issues']:
            report += f"\nâš ï¸ ×‘×¢×™×•×ª ×¡×’× ×•×Ÿ ({len(results['style_issues'])}):\n"
            for issue in results['style_issues']:
                report += f"  â€¢ {issue}\n"
        
        if results['suggestions']:
            report += f"\nğŸ’¡ ×”×¦×¢×•×ª ×œ×©×™×¤×•×¨:\n"
            for suggestion in results['suggestions']:
                report += f"  â€¢ {suggestion}\n"
        
        return report

# Global instance
quality_checker = TextQualityChecker()

def get_quality_checker() -> TextQualityChecker:
    """××—×–×™×¨ ××ª ×‘×•×“×§ ×”××™×›×•×ª ×”×’×œ×•×‘×œ×™"""
    return quality_checker

def check_text_quality(text: str) -> Dict:
    """×¤×•× ×§×¦×™×” × ×•×—×” ×œ×‘×“×™×§×ª ××™×›×•×ª ×˜×§×¡×˜"""
    return quality_checker.check_text_quality(text)

def get_improved_text(text: str) -> str:
    """×¤×•× ×§×¦×™×” × ×•×—×” ×œ×©×™×¤×•×¨ ×˜×§×¡×˜"""
    return quality_checker.get_improved_text(text)

def generate_quality_report(text: str) -> str:
    """×¤×•× ×§×¦×™×” × ×•×—×” ×œ×™×¦×™×¨×ª ×“×•×— ××™×›×•×ª"""
    return quality_checker.generate_quality_report(text)

if __name__ == "__main__":
    # ×“×•×’××” ×œ×©×™××•×©
    sample_text = """
    #TITLE# × ×™×ª×•×— ×× ×™×™×ª Apple
    
    #SUBTITLE# ×‘×™×¦×•×¢×™× ××¢×•×¨×‘×™× ×‘×¨×‘×¢×•×Ÿ ×”××—×¨×•×Ÿ
    
    #PARA# ×× ×™×™×ª Apple ×—×•×•×” ×ª× ×•×“×ª×™×•×ª ×‘×©×•×§, ×¢× ×‘×™×¦×•×¢×™× ××¢×•×¨×‘×™× ×‘×¨×‘×¢×•×Ÿ ×”××—×¨×•×Ÿ. ×”××©×§×™×¢×™× ×™×›×•×œ ×œ×¨××•×ª ×”×–×“×× ×•×™×•×ª, ××‘×œ ×”×× ×œ×™×¡×˜×™× ×”×¦×™×’ ×—×©×©×•×ª ×œ×’×‘×™ ×”×¦××™×—×” ×”×¢×ª×™×“×™×ª.
    
    #PARA# ×©×•×§ ×”×× ×™×•×ª ×©×œ Apple ×”×’×™×‘ ×‘×—×™×•×‘×™×•×ª ×œ×—×“×©×•×ª ×”××—×¨×•× ×•×ª, ××•×œ× ×”××ª×’×¨×™× × ×•×ª×¨×• ××©××¢×•×ª×™×™×.
    """
    
    print("×“×•×’××” ×œ×‘×“×™×§×ª ××™×›×•×ª ×˜×§×¡×˜:")
    print(generate_quality_report(sample_text))
    
    print("\n×˜×§×¡×˜ ××©×•×¤×¨:")
    print(get_improved_text(sample_text)) 